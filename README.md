# COMP472 Fall 2025 â€“ CIFAR-10 Classification (Naive Bayes to CNN)

### Concordia University â€” Artificial Intelligence Project

This repository contains our teamâ€™s implementation for the **COMP472** project, focusing on **image classification using the CIFAR-10 dataset**.
We begin with **Naive Bayes (Step 3)** and will later expand to **Decision Trees**, **MLP**, and **CNNs**.

---

## Setup & Installation

### Prerequisites
- **Python 3.11+**
- **pip** (latest version)

### Installation Steps

1. Upgrade pip and install dependencies:
   ```bash
   pyenv install 3.11.2
   pyenv local 3.11.2
   python -m venv .venv
   Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
   .venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. Verify setup by running the data loader:
   ```bash
   python main.py
   ```

   This will automatically download the CIFAR-10 dataset into the `./data/` directory.
   If successful, youâ€™ll see:
   ```
   Train subset size: 5000
   Test subset size: 1000
   ```

---

## ğŸ“ Repository Structure

```
COMP472_PROJECT/
â”‚
â”œâ”€â”€ data/                                 # Dataset storage (CIFAR-10 + generated features)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_pipeline/                    # Data preparation & preprocessing
â”‚   â”‚   â”œâ”€â”€ data_loader.py                # Loads & subsets CIFAR-10 (500 train + 100 test per class)
â”‚   â”‚   â”œâ”€â”€ feature_extractor.py          # Extracts 512-D ResNet-18 features
â”‚   â”‚   â”œâ”€â”€ pca_reduction.py              # Reduces feature vectors to 50-D using PCA
â”‚   â”‚   â”œâ”€â”€ run_data_pipeline.py          # Orchestrates the full preprocessing pipeline
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                           # Machine learning models
â”‚   â”‚   â”œâ”€â”€ naive_bayes.py                # Gaussian Naive Bayes (Step 3)
â”‚   â”‚   â”œâ”€â”€ decision_tree.py              # Decision Tree (Step 4)
â”‚   â”‚   â”œâ”€â”€ mlp.py                        # Multi-Layer Perceptron (Step 5)
â”‚   â”‚   â”œâ”€â”€ cnn_vgg11.py                  # CNN (Step 6)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                            # Shared utilities and metrics
â”‚   â”‚   â”œâ”€â”€ metrics.py                    # Accuracy, confusion matrix, plotting tools
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ main.py                               # Project entry point (runs full pipeline)
â”œâ”€â”€ requirements.txt                      # Python dependencies
â”œâ”€â”€ README.md                             # Project documentation
â””â”€â”€ .gitignore                            # Ignored folders (data/, __pycache__/, etc.)

```

### ğŸ§© Future Files to Be Added
- `decision_tree.py` â†’ Step 4 (Gini-based classifier)
- `mlp.py` â†’ Step 5 (3-layer PyTorch MLP)
- `cnn_vgg11.py` â†’ Step 6 (CNN training directly on images)
- `models/` â†’ Folder to store trained `.pth` or `.pkl` models

---

## âš™ï¸ Running the Full Pipeline

Once all modules are implemented, the main entry point will be:

```bash
python main.py
```

This will execute the entire flow:

1. **Load CIFAR-10 subset** (`data_loader.py`)
2. **Extract 512-D features using ResNet-18** (`feature_extract.py`)
3. **Reduce to 50-D using PCA**
4. **Train and evaluate Naive Bayes models** (`naive_bayes.py`)
5. **Print metrics and confusion matrices** (`utils.py`)

---

## ğŸ‘¥ Team Workflow

1. Install requirements (only needed once).
2. Run `python main.py` to regenerate data and models locally â€” datasets are not versioned.
3. Never commit `/data/` or `/__pycache__/`.
4. Each teammate should pull, run locally, and confirm their setup before pushing changes.

---
